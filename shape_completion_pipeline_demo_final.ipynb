{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51679dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "import cv2  \n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage.transform import resize\n",
    "from open3d.web_visualizer import draw\n",
    "\n",
    "from utils.depth_utils import *\n",
    "from utils.register_utils import *\n",
    "\n",
    "from transformers import pipeline\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "from rembg import remove\n",
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "from hy3dgen.texgen import Hunyuan3DPaintPipeline\n",
    "from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline\n",
    "\n",
    "hunyuan3D_mesh_pipe = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained('tencent/Hunyuan3D-2')\n",
    "# hunyuan3D_paint_pipe = Hunyuan3DPaintPipeline.from_pretrained('tencent/Hunyuan3D-2')\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"lllyasviel/sd-controlnet-depth\", torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "d2i_pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, safety_checker=None, torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "d2i_pipe.scheduler = UniPCMultistepScheduler.from_config(d2i_pipe.scheduler.config)\n",
    "\n",
    "# Remove if you do not have xformers installed\n",
    "# see https://huggingface.co/docs/diffusers/v0.13.0/en/optimization/xformers#installing-xformers\n",
    "# for installation instructions\n",
    "d2i_pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "d2i_pipe.enable_model_cpu_offload()\n",
    "d2i_pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2394586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_map_txt={\"01184\":\"An outdoor trash can with wheels\", # Wheelie-Bin\n",
    "              \"06127\":\"A plant in a large vase\", # vase\n",
    "              \"06830\":\"Children's tricycle with adult's handle\" , # tricycle\n",
    "              \"07306\":\"An office trash can\", # trash can\n",
    "              \"05452\":\"An a outside chair\", # arm chair\n",
    "              \"06145\":\"A one leg square table\", # table\n",
    "              \"05117\":\"A chair\", # chair\n",
    "              \"06188\": \"A Vespa scooter\", # vespa\n",
    "              \"07136\":\"A couch\", # sofa\n",
    "              \"09639\":\"An executive chair\"} # Swivel chair\n",
    "\n",
    "# params\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--obj_id\",\n",
    "    type=str,\n",
    "    default=\"09639\",\n",
    "    choices=data_map_txt.keys(),\n",
    "    help=\"Object ID to process\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--verbose\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Enable verbose output\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_dir\",\n",
    "    type=str,\n",
    "    default=\"./output\",\n",
    "    help=\"Directory to save output images\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--gen_rgb\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Generate RGB image using ControlNet\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--depth_inpainting\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Enable depth inpainting\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_gd_registration\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Use gradient descent registration\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--inference_steps\",\n",
    "    type=int,\n",
    "    default=100,\n",
    "    help=\"Number of inference steps for image generation\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",\n",
    "    type=int,\n",
    "    default=42,\n",
    "    help=\"Random seed for reproducibility\",\n",
    ")\n",
    "args = parser.parse_args(['--obj_id', '06145', \n",
    "                          '--verbose', \n",
    "                          '--gen_rgb', \n",
    "                          '--depth_inpainting', \n",
    "                          '--use_gd_registration',\n",
    "                          '--inference_steps', '50'])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c319e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "object_id = args.obj_id\n",
    "verbose = args.verbose\n",
    "depth_inpainting = args.depth_inpainting\n",
    "use_gd_registration = args.use_gd_registration\n",
    "print(\"Using GD registration:\", use_gd_registration)\n",
    "output_dir = args.output_dir\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff51190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcl_path = f'./redwood_dataset/point_clouds/{object_id}.ply'\n",
    "partial_pcl = o3d.io.read_point_cloud(pcl_path)\n",
    "partial_pcl_translate = -partial_pcl.get_center()\n",
    "partial_pcl = partial_pcl.translate(partial_pcl_translate)\n",
    "partial_pcl_scale = 1.0 / np.max(np.linalg.norm(np.asarray(partial_pcl.points), axis=1))\n",
    "partial_pcl_scale_center = np.asarray((0, 0, 0))\n",
    "partial_pcl = partial_pcl.scale(partial_pcl_scale, center=partial_pcl_scale_center)\n",
    "\n",
    "partial_pcl.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "draw([partial_pcl])\n",
    "\n",
    "partial_pcl = np.asarray(partial_pcl.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf587874",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, best_depth_map, best_depth_map_low, _ = find_best_camera_iter_w_low(partial_pcl, \n",
    "                                                                        n_cam_hull=2000, \n",
    "                                                                        n_cam_depth_iter=150, \n",
    "                                                                        radius=2.0,\n",
    "                                                                        width=512,\n",
    "                                                                        height=512,\n",
    "                                                                        fov_deg=60,\n",
    "                                                                        low_res_ratio=1/8)\n",
    "\n",
    "depth_map_c = cv2.medianBlur(best_depth_map.astype(np.float32), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_map_c, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7551992",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(best_depth_map_low, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if depth_inpainting:\n",
    "    depth_map_c = cv2.medianBlur(best_depth_map.astype(np.float32), 5)\n",
    "    # depth_map_c = cv2.medianBlur(depth_map_c.astype(np.float32), 5)\n",
    "    # depth_map_c = cv2.medianBlur(depth_map_c.astype(np.float32), 5)\n",
    "    depth_map_binary = cv2.threshold(depth_map_c, 0, 1, cv2.THRESH_BINARY)[1].astype(np.uint8)\n",
    "    depth_map_binary_low = cv2.threshold(best_depth_map_low, 0, 1, cv2.THRESH_BINARY)[1]\n",
    "    depth_map_binary_low = cv2.GaussianBlur(depth_map_binary_low, (5,5), sigmaX=1.0, sigmaY=1.0)\n",
    "    depth_map_binary_low_up = cv2.resize(depth_map_binary_low, (depth_map_c.shape[1], depth_map_c.shape[0]), interpolation=cv2.INTER_LANCZOS4)\n",
    "    depth_map_binary_low_up = cv2.threshold(depth_map_binary_low_up, 0.5, 1, cv2.THRESH_BINARY)[1].astype(np.uint8)\n",
    "    depth_map_xor = cv2.bitwise_xor(depth_map_binary, depth_map_binary_low_up)\n",
    "    depth_map_xor[depth_map_binary != 0] = 0\n",
    "    \n",
    "    from diffusers import StableDiffusionInpaintPipeline\n",
    "    from PIL import Image\n",
    "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    pipe.to(\"cuda\")\n",
    "    prompt = data_map_txt[object_id]\n",
    "    negative_prompt = \"bad anatomy, deformed, ugly, disfigured, intricate details, blurry, out of focus, bad art, bad anatomy, disfig\"\n",
    "    #image and mask_image should be PIL images.\n",
    "    # convert the depth map to a PIL image\n",
    "    depth_map_image = cv2.normalize(depth_map_c, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    depth_map_image = cv2.cvtColor(depth_map_image, cv2.COLOR_GRAY2RGB)\n",
    "    depth_map_image = cv2.resize(depth_map_image, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    # convert the binary mask to a PIL image\n",
    "    mask_image = cv2.normalize(depth_map_xor, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_GRAY2RGB)\n",
    "    mask_image = cv2.resize(mask_image, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    #The mask structure is white for inpainting and black for keeping as is\n",
    "    depth_map = pipe(prompt=prompt, \n",
    "                        negative_prompt=negative_prompt, \n",
    "                        image=Image.fromarray(depth_map_image), \n",
    "                        mask_image=Image.fromarray(mask_image),\n",
    "                num_inference_steps=100,\n",
    "                guidance_scale=2.0\n",
    "                ).images[0]\n",
    "    depth_map = np.array(depth_map)\n",
    "    make_image_grid([Image.fromarray(depth_map_image), \n",
    "                     Image.fromarray(mask_image), \n",
    "                     Image.fromarray(depth_map)], rows=1, cols=3).save(\n",
    "                         os.path.join(output_dir, f\"{object_id}_depth_inpaint.png\"))\n",
    "else:\n",
    "    # depth_map_c = cv2.medianBlur(depth_map_c.astype(np.float32), 5)\n",
    "    depth_map = cv2.normalize(depth_map_c, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    # increase a little bit contrast\n",
    "    depth_map = cv2.convertScaleAbs(depth_map, alpha=0.9, beta=0)\n",
    "    depth_map = cv2.cvtColor(depth_map, cv2.COLOR_GRAY2RGB)\n",
    "    depth_map = cv2.resize(depth_map, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    make_image_grid([Image.fromarray(depth_map)], rows=1, cols=1).save(os.path.join(output_dir, f\"{object_id}_depth.png\"))\n",
    "\n",
    "# depth_map = cv2.flip(depth_map, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_map)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc6afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gen_rgb:\n",
    "    print(\"[INFO] Depth map generated, now generating image using ControlNet...\")\n",
    "    # auxiliary_prompt = \", clean background, no people, no animals\"\n",
    "    auxiliary_prompt = \"\"\n",
    "    image = d2i_pipe(data_map_txt[object_id] + auxiliary_prompt,\n",
    "                    Image.fromarray(depth_map), \n",
    "                    num_inference_steps=args.inference_steps,\n",
    "                    # num_inference_steps=75,\n",
    "                    guidance_scale = 6.0,\n",
    "                    controlnet_conditioning_scale=1.1,\n",
    "                    negative_prompt=\"bad anatomy, deformed, ugly, disfigured, \\\n",
    "                    intricate details, blurry, out of focus, bad art, bad anatomy\",\n",
    "                    # negative_prompt = \"bad anatomy, deformed, ugly, disfigured, intricate details, blurry, out of focus, bad art, bad anatomy, disfig, intricate background\",\n",
    "                    # generator=torch.manual_seed(0),\n",
    "                    # generator=torch.manual_seed(42),\n",
    "                    ).images[0]\n",
    "    image = remove(image)\n",
    "else:\n",
    "    depth_map_gray = cv2.cvtColor(depth_map, cv2.COLOR_RGB2GRAY)\n",
    "    depth_map_gray = cv2.normalize(depth_map_gray, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    depth_map_binary = cv2.threshold(depth_map_gray, 0, 1, cv2.THRESH_BINARY)[1].astype(np.uint8)\n",
    "    depth_map_binary = cv2.medianBlur(depth_map_binary.astype(np.float32), 5)\n",
    "    depth_map_rgba = cv2.cvtColor(depth_map, cv2.COLOR_RGB2RGBA)\n",
    "    depth_map_rgba[depth_map_binary == 0] = (0, 0, 0, 0)\n",
    "    depth_map_rgba = Image.fromarray(depth_map_rgba.astype(np.uint8))\n",
    "    image = depth_map_rgba.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Image prompt for Hunyuan3D:\")\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "image.save(os.path.join(output_dir, f\"{object_id}_img_prompt.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d422f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Background removed, now generating mesh using Hunyuan3D...\")\n",
    "mesh = hunyuan3D_mesh_pipe(image=image,\n",
    "                      num_inference_steps=args.inference_steps,\n",
    "                      guidance_scale = 4.5,\n",
    "                      )[0]\n",
    "# print(\"[INFO] Mesh generated, now generating texture using Hunyuan3D...\")\n",
    "# mesh = hunyuan3D_paint_pipe(mesh=mesh,\n",
    "#                             image=image_nobg,\n",
    "#                             )[0]\n",
    "# Save the mesh to a file\n",
    "print(\"[INFO] Saving mesh...\")\n",
    "mesh.export(os.path.join(output_dir, f\"{object_id}_mesh.ply\"))\n",
    "print(f\"Mesh saved to {os.path.join(output_dir, f'{object_id}_mesh.ply')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321474b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualize the mesh\n",
    "print(\"[INFO] Visualizing mesh...\")\n",
    "mesh = o3d.io.read_triangle_mesh(os.path.join(output_dir, f\"{object_id}_mesh.ply\"))\n",
    "mesh.vertices = o3d.utility.Vector3dVector(np.asarray(mesh.vertices) * np.array([-1, 1, 1]))\n",
    "\n",
    "draw([mesh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the mesh to the original point cloud\n",
    "print(\"[INFO] Registering mesh to original point cloud...\")\n",
    "\n",
    "object_id = args.obj_id\n",
    "# object_id = \"01184\"\\\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the ground truth mesh\n",
    "complete_pcd = o3d.io.read_triangle_mesh(f\"./redwood_dataset/GT/{object_id}.ply\")\n",
    "complete_pcd = complete_pcd.sample_points_uniformly(number_of_points=16384)\n",
    "complete_pcd.points = o3d.utility.Vector3dVector(-np.asarray(complete_pcd.points))\n",
    "translate = -complete_pcd.get_center()\n",
    "complete_pcd = complete_pcd.translate(translate)\n",
    "scale = 0.5 / np.max(np.linalg.norm(np.asarray(complete_pcd.points), axis=1))\n",
    "complete_pcd = complete_pcd.scale(scale, center=complete_pcd.get_center())\n",
    "\n",
    "# Load the partial point cloud\n",
    "partial_pcd = o3d.io.read_point_cloud(f\"./redwood_dataset/point_clouds/{object_id}.ply\")\n",
    "partial_pcd.points = o3d.utility.Vector3dVector(-np.asarray(partial_pcd.points))\n",
    "partial_pcd = partial_pcd.translate(translate)\n",
    "partial_pcd = partial_pcd.scale(scale, center=complete_pcd.get_center())\n",
    "partial_pcd = partial_pcd.farthest_point_down_sample(num_samples=16384)\n",
    "\n",
    "# Load the generated mesh\n",
    "mesh = o3d.io.read_triangle_mesh(os.path.join(output_dir, f\"{object_id}_mesh.ply\"))\n",
    "# Normalize the mesh\n",
    "mesh = mesh.translate(-mesh.get_center())\n",
    "mesh = mesh.scale(0.5 / np.max(np.linalg.norm(np.asarray(mesh.vertices), axis=1)), center=mesh.get_center())\n",
    "mesh_pcd = mesh.sample_points_uniformly(number_of_points=16384)\n",
    "mesh_pcd.points = o3d.utility.Vector3dVector(np.asarray(mesh_pcd.points) * np.array([-1, 1, 1]))\n",
    "\n",
    "mesh_pcd.paint_uniform_color([1, 0, 0])\n",
    "partial_pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "# complete_pcd.paint_uniform_color([0, 1, 0])\n",
    "draw([mesh_pcd, partial_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.register_utils import multiscale_registration\n",
    "from utils.gd_register_utils import gd_registration\n",
    "\n",
    "# print(use_gd_registration)\n",
    "use_gd_registration = False\n",
    "if use_gd_registration:\n",
    "    mesh_pcd = gd_registration(mesh_pcd, \n",
    "                            partial_pcd, \n",
    "                            fps_sample=4096, \n",
    "                            num_iterations=500,\n",
    "                            learning_rate=0.9,\n",
    "                            device='cuda', \n",
    "                            stage2=False,\n",
    "                            #    isotropic_scale=False\n",
    "                            )\n",
    "else:\n",
    "    transformation = multiscale_registration(mesh_pcd, partial_pcd, voxel_size=0.005)\n",
    "    mesh_pcd.transform(transformation)\n",
    "# Compute the chamfer distance\n",
    "cd_o3d = (np.mean(complete_pcd.compute_point_cloud_distance(mesh_pcd)) + \\\n",
    "    np.mean(mesh_pcd.compute_point_cloud_distance(complete_pcd))) / 2\n",
    "print(f\"Chamfer Distance: {cd_o3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the registered mesh to a file\n",
    "o3d.io.write_point_cloud(os.path.join(output_dir, f\"{object_id}_pcd_complete_registered.ply\"), mesh_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "partial_pcd.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "complete_pcd.paint_uniform_color([0.0, 0.0, 0.5])\n",
    "draw([mesh_pcd, partial_pcd])\n",
    "draw([mesh_pcd, complete_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "draw([mesh_pcd, partial_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef89507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show run time\n",
    "end_time = time.time()\n",
    "print(f\"[INFO] Total run time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90421c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b139c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LGM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
